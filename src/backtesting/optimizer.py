"""
íŒŒë¼ë¯¸í„° ìµœì í™” ëª¨ë“ˆ (Week 4 + Week 5)

ParameterOptimizer í´ë˜ìŠ¤:
- Grid Searchë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰ (--optimize)
- multiprocessing ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›

OptunaOptimizer í´ë˜ìŠ¤:
- Bayesian Optimization (Walk-Forward Analysisìš©)
- MedianPruner: ë‚˜ìœ Trial ì¡°ê¸° ì¤‘ë‹¨
- 2ë‹¨ê³„ íƒìƒ‰: Phase 1 (ë„“ì€ ë²”ìœ„) â†’ Phase 2 (ì¢‹ì€ êµ¬ê°„ ì§‘ì¤‘)
"""

import sqlite3
import itertools
import pandas as pd
from datetime import datetime
from typing import Optional, List, Dict
from multiprocessing import Pool

from .engine import BacktestConfig, BacktestEngine
from .metrics import PerformanceMetrics


# ============================================================================
# ëª¨ë“ˆ ë ˆë²¨ worker í•¨ìˆ˜ (multiprocessing pickle í˜¸í™˜)
# ============================================================================

def _run_backtest_worker(args: tuple) -> Optional[dict]:
    """
    ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•© ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (worker í•¨ìˆ˜)

    multiprocessing.Poolì—ì„œ í˜¸ì¶œí•˜ë¯€ë¡œ ëª¨ë“ˆ ë ˆë²¨ì— ì •ì˜ (pickle ê°€ëŠ¥)

    Args:
        args: (db_path, params, start_date, end_date) íŠœí”Œ

    Returns:
        {'params': dict, ...ì„±ê³¼ ë©”íŠ¸ë¦­} ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    db_path, params, start_date, end_date = args
    conn = sqlite3.connect(db_path)
    try:
        config = BacktestConfig(**params)
        engine = BacktestEngine(conn, config)
        result = engine.run(start_date, end_date, verbose=False)
        metrics = PerformanceMetrics(
            result['trades'],
            result['daily_values'],
            config.initial_capital
        )
        summary = metrics.summary()
        return {'params': params, **summary}
    except Exception:
        return None
    finally:
        conn.close()


# ============================================================================
# ParameterOptimizer í´ë˜ìŠ¤
# ============================================================================

class ParameterOptimizer:
    """
    Grid Search ê¸°ë°˜ íŒŒë¼ë¯¸í„° ìµœì í™” í´ë˜ìŠ¤

    íƒìƒ‰ ëŒ€ìƒ íŒŒë¼ë¯¸í„°:
    - min_score: ìµœì†Œ íŒ¨í„´ ì ìˆ˜ (ì§„ì… ì¡°ê±´)
    - min_signals: ìµœì†Œ ì‹œê·¸ë„ ê°œìˆ˜ (ì§„ì… ì¡°ê±´)
    - target_return: ëª©í‘œ ìˆ˜ìµë¥  (ì²­ì‚° ì¡°ê±´)
    - stop_loss: ì†ì ˆ ë¹„ìœ¨ (ì²­ì‚° ì¡°ê±´)
    - institution_weight: ê¸°ê´€ ê°€ì¤‘ì¹˜ (normalizer íŒŒë¼ë¯¸í„°)
    """

    DEFAULT_PARAM_GRID = {
        'min_score': [60, 70, 80],
        'min_signals': [1, 2],
        'target_return': [0.10, 0.15, 0.20],
        'stop_loss': [-0.05, -0.075, -0.10],
        'institution_weight': [0.0, 0.1, 0.2, 0.3, 0.5],
    }

    def __init__(self, db_path: str, start_date: str, end_date: str,
                 base_config: Optional[BacktestConfig] = None):
        """
        ì´ˆê¸°í™”

        Args:
            db_path: SQLite DB íŒŒì¼ ê²½ë¡œ (workerì—ì„œ ì‚¬ìš©)
            start_date: ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (YYYY-MM-DD)
            end_date: ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼ (YYYY-MM-DD)
            base_config: ê¸°ë³¸ BacktestConfig (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
                param_gridì— ì—†ëŠ” íŒŒë¼ë¯¸í„°ëŠ” base_config ê°’ ì‚¬ìš©
        """
        self.db_path = db_path
        self.start_date = start_date
        self.end_date = end_date
        self.base_config = base_config or BacktestConfig()

    def grid_search(self,
                    param_grid: Optional[Dict] = None,
                    metric: str = 'sharpe_ratio',
                    top_n: int = 10,
                    workers: int = 1,
                    verbose: bool = True) -> pd.DataFrame:
        """
        Grid Search ì‹¤í–‰

        ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ë°±í…ŒìŠ¤íŠ¸í•˜ê³  metric ê¸°ì¤€ top_n ê²°ê³¼ ë°˜í™˜.

        Args:
            param_grid: íƒìƒ‰í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
                ì˜ˆ: {'min_score': [60, 70], 'institution_weight': [0.0, 0.3]}
                Noneì´ë©´ DEFAULT_PARAM_GRID ì‚¬ìš©
            metric: ìµœì í™” í‰ê°€ ì§€í‘œ
                'sharpe_ratio', 'total_return', 'win_rate', 'profit_factor'
            top_n: ìƒìœ„ Nê°œ ê²°ê³¼ ë°˜í™˜
            workers: ë³‘ë ¬ ì²˜ë¦¬ worker ìˆ˜ (1ì´ë©´ ìˆœì°¨ ì‹¤í–‰)
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€

        Returns:
            pd.DataFrame: top_n ê²°ê³¼ (metric ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)
                - íŒŒë¼ë¯¸í„° ì—´: íƒìƒ‰í•œ íŒŒë¼ë¯¸í„°
                - ì„±ê³¼ ì—´: total_return, sharpe_ratio, win_rate,
                           max_drawdown, profit_factor, total_trades
        """
        if param_grid is None:
            param_grid = self.DEFAULT_PARAM_GRID

        # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        combinations = self._build_param_combinations(param_grid)

        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ” Grid Search ì‹œì‘")
            print(f"{'='*60}")
            print(f"ê¸°ê°„: {self.start_date} ~ {self.end_date}")
            print(f"íƒìƒ‰ íŒŒë¼ë¯¸í„°: {list(param_grid.keys())}")
            print(f"ì¡°í•© ìˆ˜: {len(combinations)}ê°œ")
            print(f"í‰ê°€ ì§€í‘œ: {metric}")
            print(f"Workers: {workers}")
            print()

        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        args_list = [
            (self.db_path, params, self.start_date, self.end_date)
            for params in combinations
        ]

        if workers > 1:
            with Pool(processes=workers) as pool:
                raw_results = pool.map(_run_backtest_worker, args_list)
        else:
            raw_results = []
            for i, args in enumerate(args_list):
                result = _run_backtest_worker(args)
                raw_results.append(result)
                if verbose and (i + 1) % 10 == 0:
                    print(f"  ì§„í–‰: {i+1}/{len(args_list)} ì™„ë£Œ...")

        # ê²°ê³¼ ì •ë¦¬
        valid_results = [r for r in raw_results if r is not None]

        if not valid_results:
            if verbose:
                print("[WARN] ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # DataFrame ë³€í™˜
        rows = []
        for r in valid_results:
            row = {}
            # íŒŒë¼ë¯¸í„° ì—´
            for k, v in r['params'].items():
                row[k] = v
            # ì„±ê³¼ ì—´
            row['total_return'] = r.get('total_return', 0.0)
            row['sharpe_ratio'] = r.get('sharpe_ratio', 0.0)
            row['win_rate'] = r.get('win_rate', 0.0)
            row['max_drawdown'] = r.get('max_drawdown', 0.0)
            row['profit_factor'] = r.get('profit_factor', 0.0)
            row['total_trades'] = r.get('total_trades', 0)
            rows.append(row)

        df = pd.DataFrame(rows)

        # metric ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (max_drawdownì€ ì‘ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬)
        if metric == 'max_drawdown':
            df = df.sort_values(metric, ascending=True)
        else:
            df = df.sort_values(metric, ascending=False)

        result_df = df.head(top_n).reset_index(drop=True)

        if verbose:
            print(f"\nâœ… Grid Search ì™„ë£Œ!")
            print(f"ì´ {len(valid_results)}ê°œ ì¡°í•© ì‹¤í–‰ ì™„ë£Œ")
            self.print_results(result_df, top_n=min(top_n, 5))

        return result_df

    def _build_param_combinations(self, param_grid: Dict) -> List[Dict]:
        """
        base_configë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±

        param_gridì— ìˆëŠ” íŒŒë¼ë¯¸í„°ë§Œ ë³€ê²½í•˜ê³ ,
        ë‚˜ë¨¸ì§€ëŠ” base_config ê°’ì„ ìœ ì§€.

        Args:
            param_grid: íƒìƒ‰ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ

        Returns:
            íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        # base_configì—ì„œ ê¸°ë³¸ê°’ ì¶”ì¶œ
        base_params = {
            'initial_capital': self.base_config.initial_capital,
            'max_positions': self.base_config.max_positions,
            'min_score': self.base_config.min_score,
            'min_signals': self.base_config.min_signals,
            'target_return': self.base_config.target_return,
            'stop_loss': self.base_config.stop_loss,
            'max_hold_days': self.base_config.max_hold_days,
            'reverse_signal_threshold': self.base_config.reverse_signal_threshold,
            'strategy': self.base_config.strategy,
            'institution_weight': self.base_config.institution_weight,
            'force_exit_on_end': self.base_config.force_exit_on_end,
        }

        # param_grid í‚¤ì™€ ê°’ ëª©ë¡ ì¶”ì¶œ
        keys = list(param_grid.keys())
        value_lists = [param_grid[k] for k in keys]

        # ëª¨ë“  ì¡°í•© ìƒì„±
        combinations = []
        for values in itertools.product(*value_lists):
            params = base_params.copy()
            for k, v in zip(keys, values):
                params[k] = v
            combinations.append(params)

        return combinations

    def print_results(self, results_df: pd.DataFrame, top_n: int = 10):
        """
        ìµœì í™” ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥

        Args:
            results_df: grid_search() ë°˜í™˜ DataFrame
            top_n: ì¶œë ¥í•  ìƒìœ„ Nê°œ
        """
        if results_df.empty:
            print("[WARN] ì¶œë ¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        df = results_df.head(top_n)

        print(f"\n{'='*60}")
        print(f"ğŸ“Š ìµœì í™” ê²°ê³¼ (ìƒìœ„ {len(df)}ê°œ)")
        print(f"{'='*60}")

        # íŒŒë¼ë¯¸í„° ì—´ê³¼ ì„±ê³¼ ì—´ ë¶„ë¦¬
        perf_cols = ['total_return', 'sharpe_ratio', 'win_rate',
                     'max_drawdown', 'profit_factor', 'total_trades']
        param_cols = [c for c in df.columns if c not in perf_cols]

        for i, row in df.iterrows():
            print(f"\n[{i+1}ìœ„]")
            # íŒŒë¼ë¯¸í„°
            param_str = " | ".join([
                f"{c}={row[c]}" for c in param_cols if c in row
            ])
            print(f"  íŒŒë¼ë¯¸í„°: {param_str}")
            # ì„±ê³¼
            print(f"  ìˆ˜ìµë¥ : {row['total_return']:+.2f}% | "
                  f"ìƒ¤í”„: {row['sharpe_ratio']:.2f} | "
                  f"ìŠ¹ë¥ : {row['win_rate']:.1f}% | "
                  f"MDD: {row['max_drawdown']:.2f}% | "
                  f"PF: {row['profit_factor']:.2f} | "
                  f"ê±°ë˜: {row['total_trades']:.0f}ê±´")

        print()


# ============================================================================
# OptunaOptimizer í´ë˜ìŠ¤ (Walk-Forwardìš© Bayesian Optimization)
# ============================================================================

class OptunaOptimizer:
    """
    Optuna Bayesian Optimization ê¸°ë°˜ íŒŒë¼ë¯¸í„° ìµœì í™” í´ë˜ìŠ¤

    Walk-Forward Analysisì—ì„œ Grid Search ëŒ€ì‹  ì‚¬ìš©.
    - MedianPruner: ì ˆë°˜ ê¸°ê°„ ì¤‘ê°„ í‰ê°€ë¡œ ë‚˜ìœ Trial ì¡°ê¸° ì¤‘ë‹¨
    - 2ë‹¨ê³„ íƒìƒ‰: Phase 1 (ë„“ì€ ë²”ìœ„) â†’ Phase 2 (ì¢‹ì€ êµ¬ê°„ ì§‘ì¤‘)

    íŒŒë¼ë¯¸í„° ê³µê°„ í˜•ì‹:
        {
            'min_score':     {'type': 'float', 'low': 50.0, 'high': 90.0},
            'min_signals':   {'type': 'int',   'low': 1,    'high': 3},
        }
    """

    DEFAULT_PARAM_SPACE = {
        'min_score':          {'type': 'float', 'low': 50.0,  'high': 90.0},
        'min_signals':        {'type': 'int',   'low': 1,     'high': 3},
        'target_return':      {'type': 'float', 'low': 0.05,  'high': 0.25},
        'stop_loss':          {'type': 'float', 'low': -0.15, 'high': -0.03},
        'institution_weight': {'type': 'float', 'low': 0.0,   'high': 0.5},
    }

    def __init__(self, db_path: str, start_date: str, end_date: str,
                 base_config: Optional[BacktestConfig] = None):
        """
        Args:
            db_path: SQLite DB íŒŒì¼ ê²½ë¡œ
            start_date: ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (YYYY-MM-DD)
            end_date: ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼ (YYYY-MM-DD)
            base_config: ê¸°ë³¸ BacktestConfig (ìµœì í™” ëŒ€ìƒ ì™¸ íŒŒë¼ë¯¸í„°)
        """
        self.db_path = db_path
        self.start_date = start_date
        self.end_date = end_date
        self.base_config = base_config or BacktestConfig()

    def _build_base_params(self) -> dict:
        """base_configì—ì„œ ê¸°ë³¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        c = self.base_config
        return {
            'initial_capital': c.initial_capital,
            'max_positions': c.max_positions,
            'min_score': c.min_score,
            'min_signals': c.min_signals,
            'target_return': c.target_return,
            'stop_loss': c.stop_loss,
            'max_hold_days': c.max_hold_days,
            'reverse_signal_threshold': c.reverse_signal_threshold,
            'strategy': c.strategy,
            'institution_weight': c.institution_weight,
            'force_exit_on_end': c.force_exit_on_end,
        }

    def _build_objective(self, param_space: dict, metric: str):
        """
        Optuna objective function ìƒì„± (closure)

        MedianPruner ì§€ì›:
        - Step 0: í•™ìŠµ ê¸°ê°„ ì ˆë°˜ í‰ê°€ â†’ trial.report() â†’ prune íŒë‹¨
        - í†µê³¼ ì‹œ: ì „ì²´ ê¸°ê°„ í‰ê°€ â†’ ìµœì¢… ê°’ ë°˜í™˜
        """
        import optuna as _optuna
        db_path = self.db_path
        start_date = self.start_date
        end_date = self.end_date
        build_base = self._build_base_params
        _TrialPruned = _optuna.exceptions.TrialPruned

        def objective(trial):
            # íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
            params = build_base()
            for name, spec in param_space.items():
                if spec['type'] == 'int':
                    params[name] = trial.suggest_int(
                        name, int(spec['low']), int(spec['high']))
                else:
                    params[name] = trial.suggest_float(
                        name, spec['low'], spec['high'])

            # ì¤‘ê°„ í‰ê°€ ë‚ ì§œ (ì „ì²´ ê¸°ê°„ì˜ ì ˆë°˜)
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            mid_dt = start_dt + (end_dt - start_dt) // 2
            mid_date = mid_dt.strftime('%Y-%m-%d')

            conn = sqlite3.connect(db_path)
            try:
                config = BacktestConfig(**params)

                # Step 0: ì ˆë°˜ ê¸°ê°„ í‰ê°€ â†’ Pruning íŒë‹¨
                if mid_date > start_date:
                    engine_half = BacktestEngine(conn, config)
                    half_result = engine_half.run(start_date, mid_date, verbose=False)
                    half_trades = half_result.get('trades', [])
                    half_daily = half_result.get('daily_values', pd.DataFrame())

                    if half_trades:
                        half_m = PerformanceMetrics(
                            half_trades, half_daily, config.initial_capital
                        ).summary()
                        intermediate = float(half_m.get(metric) or float('-inf'))
                    else:
                        intermediate = float('-inf')

                    trial.report(intermediate, step=0)
                    if trial.should_prune():
                        raise _TrialPruned()

                # ì „ì²´ ê¸°ê°„ í‰ê°€
                engine_full = BacktestEngine(conn, config)
                full_result = engine_full.run(start_date, end_date, verbose=False)
                full_trades = full_result.get('trades', [])
                full_daily = full_result.get('daily_values', pd.DataFrame())

                if not full_trades:
                    return float('-inf')

                full_m = PerformanceMetrics(
                    full_trades, full_daily, config.initial_capital
                ).summary()
                return float(full_m.get(metric) or float('-inf'))

            except _TrialPruned:
                raise
            except Exception:
                return float('-inf')
            finally:
                conn.close()

        return objective

    def _narrow_param_space(self, study, param_space: dict,
                            top_pct: float = 0.25,
                            margin: float = 0.25) -> dict:
        """
        Phase 1 ê²°ê³¼ì—ì„œ ìƒìœ„ Trialì˜ íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ì¢í˜€ì„œ ë°˜í™˜

        Args:
            study: Phase 1 ì™„ë£Œëœ Optuna Study
            param_space: í˜„ì¬ íŒŒë¼ë¯¸í„° ê³µê°„
            top_pct: ìƒìœ„ ëª‡ % Trial ê¸°ì¤€ (ê¸°ë³¸: ìƒìœ„ 25%)
            margin: ìµœì†Ÿê°’/ìµœëŒ“ê°’ ê¸°ì¤€ ì—¬ìœ  ë¹„ìœ¨ (ê¸°ë³¸: 25%)

        Returns:
            ì¢í˜€ì§„ íŒŒë¼ë¯¸í„° ê³µê°„ (ë°ì´í„° ë¶€ì¡± ì‹œ ì›ë³¸ ë°˜í™˜)
        """
        import optuna as _optuna
        complete = [
            t for t in study.trials
            if t.state == _optuna.trial.TrialState.COMPLETE and t.value is not None
        ]
        if len(complete) < 4:
            return param_space  # ë°ì´í„° ë¶€ì¡± â†’ ì¢íˆì§€ ì•ŠìŒ

        n_top = max(2, int(len(complete) * top_pct))
        top_trials = sorted(complete, key=lambda t: t.value, reverse=True)[:n_top]

        narrowed = {}
        for name, spec in param_space.items():
            values = [t.params[name] for t in top_trials if name in t.params]
            if len(values) < 2:
                narrowed[name] = spec
                continue

            v_min, v_max = min(values), max(values)
            total_range = spec['high'] - spec['low']
            # íƒìƒ‰ ë²”ìœ„ì˜ ìµœì†Œ 10% í­ ìœ ì§€
            expansion = max(total_range * 0.1, (v_max - v_min) * margin)
            new_low = max(spec['low'], v_min - expansion)
            new_high = min(spec['high'], v_max + expansion)

            if spec['type'] == 'int':
                new_lo_i = max(int(spec['low']), int(new_low))
                new_hi_i = min(int(spec['high']), int(new_high) + 1)
                if new_lo_i < new_hi_i:
                    narrowed[name] = {'type': 'int', 'low': new_lo_i, 'high': new_hi_i}
                else:
                    narrowed[name] = spec
            else:
                if new_low < new_high - 1e-8:
                    narrowed[name] = {'type': 'float', 'low': new_low, 'high': new_high}
                else:
                    narrowed[name] = spec

        return narrowed

    def optimize(self, param_space: Optional[dict] = None,
                 n_trials: int = 50,
                 metric: str = 'sharpe_ratio',
                 verbose: bool = True) -> Optional[dict]:
        """
        2ë‹¨ê³„ Bayesian Optimization ì‹¤í–‰

        Phase 1 (ë„“ì€ ë²”ìœ„ íƒìƒ‰, n_trials//2 trials)
          â†’ ìƒìœ„ 25% Trialë¡œ íƒìƒ‰ ë²”ìœ„ ì¢íˆê¸°
          â†’ Phase 2 (ì§‘ì¤‘ íƒìƒ‰, ë‚˜ë¨¸ì§€ trials, Phase 1 ìµœê³ ê°’ seed)

        Args:
            param_space: íƒìƒ‰ íŒŒë¼ë¯¸í„° ê³µê°„
                Noneì´ë©´ DEFAULT_PARAM_SPACE ì‚¬ìš©
                í˜•ì‹: {'param': {'type': 'float'/'int', 'low': ..., 'high': ...}}
            n_trials: ì´ Trial ìˆ˜ (Phase 1: n//2, Phase 2: ë‚˜ë¨¸ì§€)
            metric: í‰ê°€ ì§€í‘œ
                'sharpe_ratio', 'total_return', 'win_rate',
                'profit_factor', 'max_drawdown'
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€

        Returns:
            {
                'params': BacktestConfig íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬,
                metric: float (ìµœê³  ê°’),
                'total_complete': int,
                'total_pruned': int,
            }
            ë˜ëŠ” None (ì™„ë£Œ Trial ì—†ìŒ)
        """
        import optuna as _optuna
        from optuna.pruners import MedianPruner
        _optuna.logging.set_verbosity(_optuna.logging.WARNING)

        if param_space is None:
            param_space = self.DEFAULT_PARAM_SPACE

        phase1_n = max(0, n_trials // 2)
        phase2_n = n_trials - phase1_n

        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ”® Optuna Bayesian Optimization ì‹œì‘")
            print(f"{'='*60}")
            print(f"ê¸°ê°„: {self.start_date} ~ {self.end_date}")
            print(f"ì´ Trial: {n_trials} (Phase 1: {phase1_n} | Phase 2: {phase2_n})")
            print(f"í‰ê°€ ì§€í‘œ: {metric}")
            print(f"íŒŒë¼ë¯¸í„°: {list(param_space.keys())}")

        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=0)

        # â”€â”€ Phase 1: ë„“ì€ ë²”ìœ„ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        study1 = _optuna.create_study(direction='maximize', pruner=pruner)
        study2 = None

        if phase1_n > 0:
            if verbose:
                print(f"\n[Phase 1] ë„“ì€ ë²”ìœ„ íƒìƒ‰ ({phase1_n} trials)...")
            obj1 = self._build_objective(param_space, metric)
            study1.optimize(obj1, n_trials=phase1_n, show_progress_bar=False)

            p1_complete = sum(
                1 for t in study1.trials
                if t.state == _optuna.trial.TrialState.COMPLETE
            )
            p1_pruned = sum(
                1 for t in study1.trials
                if t.state == _optuna.trial.TrialState.PRUNED
            )
            if verbose:
                print(f"  ì™„ë£Œ: {p1_complete}ê°œ | ì¤‘ë‹¨(Pruned): {p1_pruned}ê°œ")
                try:
                    print(f"  Phase 1 ìµœê³  {metric}: {study1.best_value:.4f}")
                except ValueError:
                    pass

        # â”€â”€ Phase 2: ì¢‹ì€ êµ¬ê°„ ì§‘ì¤‘ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if phase2_n > 0:
            narrowed_space = self._narrow_param_space(study1, param_space)
            if verbose:
                changed = [k for k in narrowed_space
                           if narrowed_space[k] != param_space.get(k)]
                print(f"\n[Phase 2] ì§‘ì¤‘ íƒìƒ‰ ({phase2_n} trials)...")
                if changed:
                    print(f"  ì¢í˜€ì§„ íŒŒë¼ë¯¸í„°: {changed}")

            study2 = _optuna.create_study(direction='maximize', pruner=pruner)

            # Phase 1 ìµœê³  íŒŒë¼ë¯¸í„°ë¥¼ seed trialë¡œ ì¶”ê°€
            try:
                if study1.best_trial and study1.best_trial.params:
                    study2.enqueue_trial(study1.best_trial.params)
            except (ValueError, AttributeError):
                pass

            obj2 = self._build_objective(narrowed_space, metric)
            study2.optimize(obj2, n_trials=phase2_n, show_progress_bar=False)

            p2_complete = sum(
                1 for t in study2.trials
                if t.state == _optuna.trial.TrialState.COMPLETE
            )
            p2_pruned = sum(
                1 for t in study2.trials
                if t.state == _optuna.trial.TrialState.PRUNED
            )
            if verbose:
                print(f"  ì™„ë£Œ: {p2_complete}ê°œ | ì¤‘ë‹¨(Pruned): {p2_pruned}ê°œ")
                try:
                    print(f"  Phase 2 ìµœê³  {metric}: {study2.best_value:.4f}")
                except ValueError:
                    pass

        # â”€â”€ ì „ì²´ ê²°ê³¼ì—ì„œ ìµœê³  Trial ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        all_complete = [
            t for t in study1.trials
            if t.state == _optuna.trial.TrialState.COMPLETE
        ]
        if study2:
            all_complete += [
                t for t in study2.trials
                if t.state == _optuna.trial.TrialState.COMPLETE
            ]

        if not all_complete:
            if verbose:
                print("\n[WARN] ì™„ë£Œëœ Trialì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        best_trial = max(all_complete, key=lambda t: t.value)

        # best_trial íŒŒë¼ë¯¸í„° â†’ BacktestConfig íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        best_params = self._build_base_params()
        for name in param_space:
            if name in best_trial.params:
                best_params[name] = best_trial.params[name]

        all_trials = study1.trials + (study2.trials if study2 else [])
        total_pruned = sum(
            1 for t in all_trials
            if t.state == _optuna.trial.TrialState.PRUNED
        )

        if verbose:
            print(f"\n{'='*60}")
            print(f"âœ… Optuna ìµœì í™” ì™„ë£Œ!")
            print(f"ì™„ë£Œ Trial: {len(all_complete)}ê°œ | ì¤‘ë‹¨ Trial: {total_pruned}ê°œ")
            print(f"ìµœê³  {metric}: {best_trial.value:.4f}")
            param_parts = []
            for k in param_space:
                v = best_params[k]
                param_parts.append(
                    f"{k}={v:.3f}" if isinstance(v, float) else f"{k}={v}"
                )
            print(f"ìµœì  íŒŒë¼ë¯¸í„°: {' | '.join(param_parts)}")
            print(f"{'='*60}\n")

        return {
            'params': best_params,
            metric: best_trial.value,
            'total_complete': len(all_complete),
            'total_pruned': total_pruned,
        }

    def print_results(self, result: Optional[dict], metric: str = 'sharpe_ratio'):
        """ìµœì í™” ê²°ê³¼ ì¶œë ¥"""
        if result is None:
            print("[WARN] ì¶œë ¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*60}")
        print(f"ğŸ“Š Optuna ìµœì í™” ê²°ê³¼")
        print(f"{'='*60}")
        print(f"ìµœê³  {metric}: {result.get(metric, 'N/A')}")
        print(f"ì™„ë£Œ Trial: {result.get('total_complete', 'N/A')}")
        print(f"ì¤‘ë‹¨ Trial: {result.get('total_pruned', 'N/A')}")
        params = result.get('params', {})
        print(f"\nìµœì  íŒŒë¼ë¯¸í„°:")
        for k, v in params.items():
            if k not in {'initial_capital', 'force_exit_on_end'}:
                print(f"  {k}: {v:.4f}" if isinstance(v, float) else f"  {k}: {v}")
        print()
