"""
íŒŒë¼ë¯¸í„° ìµœì í™” ëª¨ë“ˆ

OptunaOptimizer í´ë˜ìŠ¤:
- Bayesian Optimization (--optimize ë° Walk-Forward Analysis ê³µìš©)
- MedianPruner: ë‚˜ìœ Trial ì¡°ê¸° ì¤‘ë‹¨
- 2ë‹¨ê³„ íƒìƒ‰: Phase 1 (ë„“ì€ ë²”ìœ„) â†’ Phase 2 (ì¢‹ì€ êµ¬ê°„ ì§‘ì¤‘)
"""

import sqlite3
import pandas as pd
from datetime import datetime
from typing import Optional, Dict

from .engine import BacktestConfig, BacktestEngine
from .precomputer import BacktestPrecomputer
from .metrics import PerformanceMetrics


# ============================================================================
# OptunaOptimizer í´ë˜ìŠ¤ (Bayesian Optimization)
# ============================================================================

class OptunaOptimizer:
    """
    Optuna Bayesian Optimization ê¸°ë°˜ íŒŒë¼ë¯¸í„° ìµœì í™” í´ë˜ìŠ¤

    --optimize ë° Walk-Forward Analysis ê³µìš©.
    - MedianPruner: ì ˆë°˜ ê¸°ê°„ ì¤‘ê°„ í‰ê°€ë¡œ ë‚˜ìœ Trial ì¡°ê¸° ì¤‘ë‹¨
    - 2ë‹¨ê³„ íƒìƒ‰: Phase 1 (ë„“ì€ ë²”ìœ„) â†’ Phase 2 (ì¢‹ì€ êµ¬ê°„ ì§‘ì¤‘)

    íŒŒë¼ë¯¸í„° ê³µê°„ í˜•ì‹:
        {
            'min_score':     {'type': 'float', 'low': 50.0, 'high': 90.0},
            'min_signals':   {'type': 'int',   'low': 1,    'high': 3},
        }
    """

    DEFAULT_PARAM_SPACE = {
        'min_score':     {'type': 'float', 'low': 50.0,  'high': 90.0},
        'min_signals':   {'type': 'int',   'low': 1,     'high': 3},
        'target_return': {'type': 'float', 'low': 0.05,  'high': 0.25},
        'stop_loss':     {'type': 'float', 'low': -0.15, 'high': -0.03},
        # institution_weightëŠ” ë¶„ì„ ì² í•™ íŒŒë¼ë¯¸í„° (ì „ëµ ìµœì í™” ëŒ€ìƒ ì•„ë‹˜)
        # BacktestConfigì˜ ê³ ì • íŒŒë¼ë¯¸í„°ë¡œ ê´€ë¦¬ (ê¸°ë³¸ê°’: 0.3)
    }

    def __init__(self, db_path: str, start_date: str, end_date: str,
                 base_config: Optional[BacktestConfig] = None):
        """
        Args:
            db_path: SQLite DB íŒŒì¼ ê²½ë¡œ
            start_date: ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (YYYY-MM-DD)
            end_date: ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼ (YYYY-MM-DD)
            base_config: ê¸°ë³¸ BacktestConfig (ìµœì í™” ëŒ€ìƒ ì™¸ íŒŒë¼ë¯¸í„°)
        """
        self.db_path = db_path
        self.start_date = start_date
        self.end_date = end_date
        self.base_config = base_config or BacktestConfig()

    def _build_base_params(self) -> dict:
        """base_configì—ì„œ ê¸°ë³¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        c = self.base_config
        return {
            'initial_capital': c.initial_capital,
            'max_positions': c.max_positions,
            'min_score': c.min_score,
            'min_signals': c.min_signals,
            'target_return': c.target_return,
            'stop_loss': c.stop_loss,
            'max_hold_days': c.max_hold_days,
            'reverse_signal_threshold': c.reverse_signal_threshold,
            'strategy': c.strategy,
            'institution_weight': c.institution_weight,
            'force_exit_on_end': c.force_exit_on_end,
        }

    def _build_objective(self, param_space: dict, metric: str,
                         precomputed=None):
        """
        Optuna objective function ìƒì„± (closure)

        MedianPruner ì§€ì›:
        - Step 0: í•™ìŠµ ê¸°ê°„ ì ˆë°˜ í‰ê°€ â†’ trial.report() â†’ prune íŒë‹¨
        - í†µê³¼ ì‹œ: ì „ì²´ ê¸°ê°„ í‰ê°€ â†’ ìµœì¢… ê°’ ë°˜í™˜

        Args:
            precomputed: PrecomputeResult (ì™¸ë¶€ ì£¼ì… ì‹œ Trial ê°„ ê³µìœ , Noneì´ë©´ Trialë§ˆë‹¤ ê³„ì‚°)
        """
        import optuna as _optuna
        db_path = self.db_path
        start_date = self.start_date
        end_date = self.end_date
        build_base = self._build_base_params
        _TrialPruned = _optuna.exceptions.TrialPruned

        def objective(trial):
            # íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
            params = build_base()
            for name, spec in param_space.items():
                if spec['type'] == 'int':
                    params[name] = trial.suggest_int(
                        name, int(spec['low']), int(spec['high']))
                else:
                    params[name] = trial.suggest_float(
                        name, spec['low'], spec['high'])

            # ì¤‘ê°„ í‰ê°€ ë‚ ì§œ (ì „ì²´ ê¸°ê°„ì˜ ì ˆë°˜)
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            mid_dt = start_dt + (end_dt - start_dt) // 2
            mid_date = mid_dt.strftime('%Y-%m-%d')

            conn = sqlite3.connect(db_path)
            try:
                config = BacktestConfig(**params)

                # Step 0: ì ˆë°˜ ê¸°ê°„ í‰ê°€ â†’ Pruning íŒë‹¨
                # precomputed ì£¼ì… ì‹œ: ì „ì²´ ê¸°ê°„ ì‚¬ì „ ê³„ì‚° ë°ì´í„°ë¥¼ ì ˆë°˜ ë£¨í”„ì—ë„ ì¬ì‚¬ìš©
                # (rollingì€ backward-lookingì´ë¯€ë¡œ ë¯¸ë˜ ëˆ„ìˆ˜ ì—†ìŒ)
                if mid_date > start_date:
                    engine_half = BacktestEngine(conn, config)
                    half_result = engine_half.run(
                        start_date, mid_date, verbose=False,
                        preload_data=(precomputed is None),
                        precomputed=precomputed,
                    )
                    half_trades = half_result.get('trades', [])
                    half_daily = half_result.get('daily_values', pd.DataFrame())

                    if half_trades:
                        half_m = PerformanceMetrics(
                            half_trades, half_daily, config.initial_capital
                        ).summary()
                        intermediate = float(half_m.get(metric) or float('-inf'))
                    else:
                        intermediate = float('-inf')

                    trial.report(intermediate, step=0)
                    if trial.should_prune():
                        raise _TrialPruned()

                # ì „ì²´ ê¸°ê°„ í‰ê°€
                engine_full = BacktestEngine(conn, config)
                full_result = engine_full.run(
                    start_date, end_date, verbose=False,
                    preload_data=(precomputed is None),
                    precomputed=precomputed,
                )
                full_trades = full_result.get('trades', [])
                full_daily = full_result.get('daily_values', pd.DataFrame())

                if not full_trades:
                    return float('-inf')

                full_m = PerformanceMetrics(
                    full_trades, full_daily, config.initial_capital
                ).summary()
                return float(full_m.get(metric) or float('-inf'))

            except _TrialPruned:
                raise
            except Exception:
                return float('-inf')
            finally:
                conn.close()

        return objective

    def _narrow_param_space(self, study, param_space: dict,
                            top_pct: float = 0.25,
                            margin: float = 0.25) -> dict:
        """
        Phase 1 ê²°ê³¼ì—ì„œ ìƒìœ„ Trialì˜ íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ì¢í˜€ì„œ ë°˜í™˜

        Args:
            study: Phase 1 ì™„ë£Œëœ Optuna Study
            param_space: í˜„ì¬ íŒŒë¼ë¯¸í„° ê³µê°„
            top_pct: ìƒìœ„ ëª‡ % Trial ê¸°ì¤€ (ê¸°ë³¸: ìƒìœ„ 25%)
            margin: ìµœì†Ÿê°’/ìµœëŒ“ê°’ ê¸°ì¤€ ì—¬ìœ  ë¹„ìœ¨ (ê¸°ë³¸: 25%)

        Returns:
            ì¢í˜€ì§„ íŒŒë¼ë¯¸í„° ê³µê°„ (ë°ì´í„° ë¶€ì¡± ì‹œ ì›ë³¸ ë°˜í™˜)
        """
        import optuna as _optuna
        complete = [
            t for t in study.trials
            if t.state == _optuna.trial.TrialState.COMPLETE and t.value is not None
        ]
        if len(complete) < 4:
            return param_space  # ë°ì´í„° ë¶€ì¡± â†’ ì¢íˆì§€ ì•ŠìŒ

        n_top = max(2, int(len(complete) * top_pct))
        top_trials = sorted(complete, key=lambda t: t.value, reverse=True)[:n_top]

        narrowed = {}
        for name, spec in param_space.items():
            values = [t.params[name] for t in top_trials if name in t.params]
            if len(values) < 2:
                narrowed[name] = spec
                continue

            v_min, v_max = min(values), max(values)
            total_range = spec['high'] - spec['low']
            # íƒìƒ‰ ë²”ìœ„ì˜ ìµœì†Œ 10% í­ ìœ ì§€
            expansion = max(total_range * 0.1, (v_max - v_min) * margin)
            new_low = max(spec['low'], v_min - expansion)
            new_high = min(spec['high'], v_max + expansion)

            if spec['type'] == 'int':
                new_lo_i = max(int(spec['low']), int(new_low))
                new_hi_i = min(int(spec['high']), int(new_high) + 1)
                if new_lo_i < new_hi_i:
                    narrowed[name] = {'type': 'int', 'low': new_lo_i, 'high': new_hi_i}
                else:
                    narrowed[name] = spec
            else:
                if new_low < new_high - 1e-8:
                    narrowed[name] = {'type': 'float', 'low': new_low, 'high': new_high}
                else:
                    narrowed[name] = spec

        return narrowed

    def optimize(self, param_space: Optional[dict] = None,
                 n_trials: int = 50,
                 metric: str = 'sharpe_ratio',
                 verbose: bool = True) -> Optional[dict]:
        """
        2ë‹¨ê³„ Bayesian Optimization ì‹¤í–‰

        Phase 1 (ë„“ì€ ë²”ìœ„ íƒìƒ‰, n_trials//2 trials)
          â†’ ìƒìœ„ 25% Trialë¡œ íƒìƒ‰ ë²”ìœ„ ì¢íˆê¸°
          â†’ Phase 2 (ì§‘ì¤‘ íƒìƒ‰, ë‚˜ë¨¸ì§€ trials, Phase 1 ìµœê³ ê°’ seed)

        Args:
            param_space: íƒìƒ‰ íŒŒë¼ë¯¸í„° ê³µê°„
                Noneì´ë©´ DEFAULT_PARAM_SPACE ì‚¬ìš©
                í˜•ì‹: {'param': {'type': 'float'/'int', 'low': ..., 'high': ...}}
            n_trials: ì´ Trial ìˆ˜ (Phase 1: n//2, Phase 2: ë‚˜ë¨¸ì§€)
            metric: í‰ê°€ ì§€í‘œ
                'sharpe_ratio', 'total_return', 'win_rate',
                'profit_factor', 'max_drawdown'
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€

        Returns:
            {
                'params': BacktestConfig íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬,
                metric: float (ìµœê³  ê°’),
                'total_complete': int,
                'total_pruned': int,
            }
            ë˜ëŠ” None (ì™„ë£Œ Trial ì—†ìŒ)
        """
        import optuna as _optuna
        from optuna.pruners import MedianPruner
        _optuna.logging.set_verbosity(_optuna.logging.WARNING)

        if param_space is None:
            param_space = self.DEFAULT_PARAM_SPACE

        phase1_n = max(0, n_trials // 2)
        phase2_n = n_trials - phase1_n

        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ”® Optuna Bayesian Optimization ì‹œì‘")
            print(f"{'='*60}")
            print(f"ê¸°ê°„: {self.start_date} ~ {self.end_date}")
            print(f"ì´ Trial: {n_trials} (Phase 1: {phase1_n} | Phase 2: {phase2_n})")
            print(f"í‰ê°€ ì§€í‘œ: {metric}")
            print(f"íŒŒë¼ë¯¸í„°: {list(param_space.keys())}")

        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=0)

        # â”€â”€ Precomputer 1íšŒ ì‹¤í–‰ (ëª¨ë“  Trial ê³µìœ ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # institution_weightëŠ” base_config ê³ ì •ê°’ ì‚¬ìš© (ìµœì í™” ëŒ€ìƒ ì•„ë‹˜)
        # â†’ Phase 1/2 ì „ì²´ Trialì´ ë™ì¼í•œ Precomputed ë°ì´í„°ë¥¼ ì¬ì‚¬ìš©
        if verbose:
            print(f"\n[Precompute] ì‚¬ì „ ê³„ì‚° ì¤‘ (ëª¨ë“  Trial ê³µìœ )...")
        conn_pre = sqlite3.connect(self.db_path)
        try:
            pc = BacktestPrecomputer(conn_pre, self.base_config.institution_weight)
            shared_precomputed = pc.precompute(
                self.end_date, start_date=self.start_date, verbose=verbose
            )
        finally:
            conn_pre.close()
        if verbose:
            print(f"[Precompute] ì™„ë£Œ â†’ {n_trials} Trialì— ê³µìœ \n")

        # â”€â”€ Phase 1: ë„“ì€ ë²”ìœ„ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        sampler = _optuna.samplers.TPESampler(seed=42)
        study1 = _optuna.create_study(direction='maximize', pruner=pruner,
                                      sampler=sampler)
        study2 = None

        if phase1_n > 0:
            if verbose:
                print(f"[Phase 1] ë„“ì€ ë²”ìœ„ íƒìƒ‰ ({phase1_n} trials)...")
            obj1 = self._build_objective(param_space, metric,
                                         precomputed=shared_precomputed)
            study1.optimize(obj1, n_trials=phase1_n, show_progress_bar=False)

            p1_complete = sum(
                1 for t in study1.trials
                if t.state == _optuna.trial.TrialState.COMPLETE
            )
            p1_pruned = sum(
                1 for t in study1.trials
                if t.state == _optuna.trial.TrialState.PRUNED
            )
            if verbose:
                print(f"  ì™„ë£Œ: {p1_complete}ê°œ | ì¤‘ë‹¨(Pruned): {p1_pruned}ê°œ")
                try:
                    print(f"  Phase 1 ìµœê³  {metric}: {study1.best_value:.4f}")
                except ValueError:
                    pass

        # â”€â”€ Phase 2: ì¢‹ì€ êµ¬ê°„ ì§‘ì¤‘ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if phase2_n > 0:
            narrowed_space = self._narrow_param_space(study1, param_space)
            if verbose:
                changed = [k for k in narrowed_space
                           if narrowed_space[k] != param_space.get(k)]
                print(f"\n[Phase 2] ì§‘ì¤‘ íƒìƒ‰ ({phase2_n} trials)...")
                if changed:
                    print(f"  ì¢í˜€ì§„ íŒŒë¼ë¯¸í„°: {changed}")

            study2 = _optuna.create_study(direction='maximize', pruner=pruner,
                                          sampler=_optuna.samplers.TPESampler(seed=42))

            # Phase 1 ìµœê³  íŒŒë¼ë¯¸í„°ë¥¼ seed trialë¡œ ì¶”ê°€
            try:
                if study1.best_trial and study1.best_trial.params:
                    study2.enqueue_trial(study1.best_trial.params)
            except (ValueError, AttributeError):
                pass

            obj2 = self._build_objective(narrowed_space, metric,
                                          precomputed=shared_precomputed)
            study2.optimize(obj2, n_trials=phase2_n, show_progress_bar=False)

            p2_complete = sum(
                1 for t in study2.trials
                if t.state == _optuna.trial.TrialState.COMPLETE
            )
            p2_pruned = sum(
                1 for t in study2.trials
                if t.state == _optuna.trial.TrialState.PRUNED
            )
            if verbose:
                print(f"  ì™„ë£Œ: {p2_complete}ê°œ | ì¤‘ë‹¨(Pruned): {p2_pruned}ê°œ")
                try:
                    print(f"  Phase 2 ìµœê³  {metric}: {study2.best_value:.4f}")
                except ValueError:
                    pass

        # â”€â”€ ì „ì²´ ê²°ê³¼ì—ì„œ ìµœê³  Trial ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        all_complete = [
            t for t in study1.trials
            if t.state == _optuna.trial.TrialState.COMPLETE
        ]
        if study2:
            all_complete += [
                t for t in study2.trials
                if t.state == _optuna.trial.TrialState.COMPLETE
            ]

        if not all_complete:
            if verbose:
                print("\n[WARN] ì™„ë£Œëœ Trialì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        best_trial = max(all_complete, key=lambda t: t.value)

        # best_trial íŒŒë¼ë¯¸í„° â†’ BacktestConfig íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        best_params = self._build_base_params()
        for name in param_space:
            if name in best_trial.params:
                best_params[name] = best_trial.params[name]

        all_trials = study1.trials + (study2.trials if study2 else [])
        total_pruned = sum(
            1 for t in all_trials
            if t.state == _optuna.trial.TrialState.PRUNED
        )

        if verbose:
            print(f"\n{'='*60}")
            print(f"âœ… Optuna ìµœì í™” ì™„ë£Œ!")
            print(f"ì™„ë£Œ Trial: {len(all_complete)}ê°œ | ì¤‘ë‹¨ Trial: {total_pruned}ê°œ")
            print(f"ìµœê³  {metric}: {best_trial.value:.4f}")
            param_parts = []
            for k in param_space:
                v = best_params[k]
                param_parts.append(
                    f"{k}={v:.3f}" if isinstance(v, float) else f"{k}={v}"
                )
            print(f"ìµœì  íŒŒë¼ë¯¸í„°: {' | '.join(param_parts)}")
            print(f"{'='*60}\n")

        return {
            'params': best_params,
            metric: best_trial.value,
            'total_complete': len(all_complete),
            'total_pruned': total_pruned,
        }

    def print_results(self, result: Optional[dict], metric: str = 'sharpe_ratio'):
        """ìµœì í™” ê²°ê³¼ ì¶œë ¥"""
        if result is None:
            print("[WARN] ì¶œë ¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*60}")
        print(f"ğŸ“Š Optuna ìµœì í™” ê²°ê³¼")
        print(f"{'='*60}")
        print(f"ìµœê³  {metric}: {result.get(metric, 'N/A')}")
        print(f"ì™„ë£Œ Trial: {result.get('total_complete', 'N/A')}")
        print(f"ì¤‘ë‹¨ Trial: {result.get('total_pruned', 'N/A')}")
        params = result.get('params', {})
        print(f"\nìµœì  íŒŒë¼ë¯¸í„°:")
        for k, v in params.items():
            if k not in {'initial_capital', 'force_exit_on_end'}:
                print(f"  {k}: {v:.4f}" if isinstance(v, float) else f"  {k}: {v}")
        print()
